# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SFt2GOJWvEGmXAv4bmMtGtpFVsaE0m72
"""

!pip install konlpy

!curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash

#from konlpy.tag import Okt, Mecab

#okt = Okt()
#mecab = Mecab()

#me=mecab.morphs('한글 형태소 분석기(광고,미켑)로 테스트를 해보았습니다. 정상 제공 설치 및 동작이 잘 됩니다.')

test=['광고','소정','원고료',
      '제공','육회','고기']

for i in me:
  for j in range(len(test)):
    if (test[j]==i):
      print('안녕')

#for i in me:
#  print(i)

import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import urllib.request
from collections import Counter
from konlpy.tag import Mecab
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

df = pd.read_csv("/content/review_data.csv")
df

#print('전체 리뷰 개수 :',len(df)) # 전체 리뷰 개수 출력

#total_data

#total_data['ratings'].nunique(), total_data['reviews'].nunique()

#total_data.drop_duplicates(subset=['reviews'], inplace=True) # reviews 열에서 중복인 내용이 있다면 중복 제거
#print('총 샘플의 수 :',len(total_data))

#print(total_data.isnull().values.any())

#train_data, test_data = train_test_split(total_data, test_size = 0.25, random_state = 42)
#print('훈련용 리뷰의 개수 :', len(train_data))
#print('테스트용 리뷰의 개수 :', len(test_data))

# 한글과 공백을 제외하고 모두 제거
#train_data['reviews'] = train_data['reviews'].str.replace("[^ㄱ-ㅎㅏ-ㅣ가-힣 ]","")
#train_data['reviews'].replace('', np.nan, inplace=True)
#print(train_data.isnull().sum())

#test_data.drop_duplicates(subset = ['reviews'], inplace=True) # 중복 제거
#test_data['reviews'] = test_data['reviews'].str.replace("[^ㄱ-ㅎㅏ-ㅣ가-힣 ]","") # 정규 표현식 수행
#test_data['reviews'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경
#test_data = test_data.dropna(how='any') # Null 값 제거
#print('전처리 후 테스트용 샘플의 개수 :',len(test_data))

#rain_data['tokenized'] = train_data['reviews'].apply(mecab.morphs)
#train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])
#train_data['to'] = train_data['tokenized'].apply(lambda x: [item for item in x if item in test])
#train_data['to']

train_data['tokenized'] = train_data['reviews'].apply(mecab.morphs)

#me=train_data['tokenized']
#me

#for i in me:
#  print(i[0])

#train_data['tokenized'][0]

me1=list(df['review'])
for i in me1:
  for j in range(len(test)):
      if (test[j] in i):
        print(test[j])
        df['lable']=1
      else:
        df['lable']=0

df['vavo']=0
for i in me1:
  for j in range(len(test)):
      df.loc[df['review'].str.contains(test[j]),'vavo']=1

df





